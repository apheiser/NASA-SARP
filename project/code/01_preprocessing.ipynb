pip install hypercoast

import os
import xarray as xr
import numpy as np
import geopandas as gpd
import unittest
import hypercoast
import os
import earthaccess
earthaccess.login()

def quality_mask(filepath, quality_bands):
    """
    Builds a single layer mask to apply based on the bands selected from an EMIT L2A Mask file.

    Args:
        filepath (str): An EMIT L2A Mask netCDF file.
        quality_bands (list): A list of bands (quality flags only) from the mask file that should be used in creation of mask.

    Returns:
        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a quality mask.

    Raises:
        AttributeError: If the selected flags include a data band (5 or 6) not just flag bands.
    """
    # Open Dataset
    mask_ds = xr.open_dataset(filepath, engine="h5netcdf")
    # Open Sensor band Group
    mask_parameters_ds = xr.open_dataset(
        filepath, engine="h5netcdf", group="sensor_band_parameters"
    )
    # Print Flags used
    flags_used = mask_parameters_ds["mask_bands"].data[quality_bands]
    print(f"Flags used: {flags_used}")
    # Check for data bands and build mask
    if any(x in quality_bands for x in [5, 6]):
        err_str = f"Selected flags include a data band (5 or 6) not just flag bands"
        raise AttributeError(err_str)
    else:
        qmask = np.sum(mask_ds["mask"][:, :, quality_bands].values, axis=-1)
        qmask[qmask > 1] = 1
    return qmask

def band_mask(filepath):
    """
    Unpacks the packed band mask to apply to the dataset. Can be used manually or as an input in the emit_xarray() function.

    Args:
        filepath (str): An EMIT L2A Mask netCDF file.

    Returns:
        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a band mask.
    """
    # Open Dataset
    mask_ds = xr.open_dataset(filepath, engine="h5netcdf")
    # Open band_mask and convert to uint8
    bmask = mask_ds.band_mask.data.astype("uint8")
    # Print Flags used
    unpacked_bmask = np.unpackbits(bmask, axis=-1)
    # Remove bands > 285
    unpacked_bmask = unpacked_bmask[:, :, 0:285]
    # Check for data bands and build mask
    return unpacked_bmask

def emit_xarray(
    filepath,
    ortho=False,
    qmask=None,
    unpacked_bmask=None,
    wavelengths=None,
    method="nearest",
):
    """
    Streamlines opening an EMIT dataset as an xarray.Dataset.

    Args:
        filepath (str): A filepath to an EMIT netCDF file.
        ortho (bool, optional): Whether to orthorectify the dataset or leave in crosstrack/downtrack coordinates. Defaults to False.
        qmask (numpy.ndarray, optional): A numpy array output from the quality_mask function used to mask pixels based on quality flags selected in that function. Any non-orthorectified array with the proper crosstrack and downtrack dimensions can also be used. Defaults to None.
        unpacked_bmask (numpy.ndarray, optional): A numpy array from the band_mask function that can be used to mask band-specific pixels that have been interpolated. Defaults to None.
        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.
        method (str, optional): The method to use for data selection. Defaults to "nearest".

    Returns:
        xarray.Dataset: An xarray.Dataset constructed based on the parameters provided.
    """
    # Grab granule filename to check product
    import s3fs
    from fsspec.implementations.http import HTTPFile

    if type(filepath) == s3fs.core.S3File:
        granule_id = filepath.info()["name"].split("/", -1)[-1].split(".", -1)[0]
    elif type(filepath) == HTTPFile:
        granule_id = filepath.path.split("/", -1)[-1].split(".", -1)[0]
    else:
        granule_id = os.path.splitext(os.path.basename(filepath))[0]

    # Read in Data as Xarray Datasets
    engine, wvl_group = "h5netcdf", None

    ds = xr.open_dataset(filepath, engine=engine)
    loc = xr.open_dataset(filepath, engine=engine, group="location")

    # Check if mineral dataset and read in groups (only ds/loc for minunc)

    if "L2B_MIN_" in granule_id:
        wvl_group = "mineral_metadata"
    elif "L2B_MINUNC" not in granule_id:
        wvl_group = "sensor_band_parameters"

    wvl = None

    if wvl_group:
        wvl = xr.open_dataset(filepath, engine=engine, group=wvl_group)

    # Building Flat Dataset from Components
    data_vars = {**ds.variables}

    # Format xarray coordinates based upon emit product (no wvl for mineral uncertainty)
    coords = {
        "downtrack": (["downtrack"], ds.downtrack.data),
        "crosstrack": (["crosstrack"], ds.crosstrack.data),
        **loc.variables,
    }

    product_band_map = {
        "L2B_MIN_": "name",
        "L2A_MASK_": "mask_bands",
        "L1B_OBS_": "observation_bands",
        "L2A_RFL_": "wavelengths",
        "L1B_RAD_": "wavelengths",
        "L2A_RFLUNCERT_": "wavelengths",
    }

    # if band := product_band_map.get(next((k for k in product_band_map.keys() if k in granule_id), 'unknown'), None):
    # coords['bands'] = wvl[band].data

    if wvl:
        coords = {**coords, **wvl.variables}

    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)
    out_xr.attrs["granule_id"] = granule_id

    if band := product_band_map.get(
        next((k for k in product_band_map.keys() if k in granule_id), "unknown"), None
    ):
        if "minerals" in list(out_xr.dims):
            out_xr = out_xr.swap_dims({"minerals": band})
            out_xr = out_xr.rename({band: "mineral_name"})
        else:
            out_xr = out_xr.swap_dims({"bands": band})

    # Apply Quality and Band Masks, set fill values to NaN
    for var in list(ds.data_vars):
        if qmask is not None:
            out_xr[var].data[qmask == 1] = np.nan
        if unpacked_bmask is not None:
            out_xr[var].data[unpacked_bmask == 1] = np.nan
        out_xr[var].data[out_xr[var].data == -9999] = np.nan

    if ortho is True:
        out_xr = ortho_xr(out_xr)
        out_xr.attrs["Orthorectified"] = "True"

    if wavelengths is not None:
        out_xr = out_xr.sel(wavelengths=wavelengths, method=method)

    out_xr = out_xr.rename({"wavelengths": "wavelength"})
    return out_xr

def ortho_xr(ds, GLT_NODATA_VALUE=0, fill_value=-9999):
    """
    Uses `apply_glt` to create an orthorectified xarray dataset.

    Args:
        ds (xarray.Dataset): An xarray dataset produced by emit_xarray.
        GLT_NODATA_VALUE (int, optional): No data value for the GLT tables. Defaults to 0.
        fill_value (int, optional): The fill value for EMIT datasets. Defaults to -9999.

    Returns:
        xarray.Dataset: An orthocorrected xarray dataset.
    """
    # Build glt_ds

    glt_ds = np.nan_to_num(
        np.stack([ds["glt_x"].data, ds["glt_y"].data], axis=-1), nan=GLT_NODATA_VALUE
    ).astype(int)

    # List Variables
    var_list = list(ds.data_vars)

    # Remove flat field from data vars - the flat field is only useful with additional information before orthorectification
    if "flat_field_update" in var_list:
        var_list.remove("flat_field_update")

    # Create empty dictionary for orthocorrected data vars
    data_vars = {}

    # Extract Rawspace Dataset Variable Values (Typically Reflectance)
    for var in var_list:
        raw_ds = ds[var].data
        var_dims = ds[var].dims
        # Apply GLT to dataset
        out_ds = apply_glt(raw_ds, glt_ds, GLT_NODATA_VALUE=GLT_NODATA_VALUE)

        # Mask fill values
        out_ds[out_ds == fill_value] = np.nan

        # Update variables - Only works for 2 or 3 dimensional arays
        if raw_ds.ndim == 2:
            out_ds = out_ds.squeeze()
            data_vars[var] = (["latitude", "longitude"], out_ds)
        else:
            data_vars[var] = (["latitude", "longitude", var_dims[-1]], out_ds)

        del raw_ds

    # Calculate Lat and Lon Vectors
    lon, lat = coord_vects(
        ds
    )  # Reorder this function to make sense in case of multiple variables

    # Apply GLT to elevation
    elev_ds = apply_glt(ds["elev"].data, glt_ds)
    elev_ds[elev_ds == fill_value] = np.nan

    # Delete glt_ds - no longer needed
    del glt_ds

    # Create Coordinate Dictionary
    coords = {
        "latitude": (["latitude"], lat),
        "longitude": (["longitude"], lon),
        **ds.coords,
    }  # unpack to add appropriate coordinates

    # Remove Unnecessary Coords
    for key in ["downtrack", "crosstrack", "lat", "lon", "glt_x", "glt_y", "elev"]:
        del coords[key]

    # Add Orthocorrected Elevation
    coords["elev"] = (["latitude", "longitude"], np.squeeze(elev_ds))

    # Build Output xarray Dataset and assign data_vars array attributes
    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)

    del out_ds
    # Assign Attributes from Original Datasets
    for var in var_list:
        out_xr[var].attrs = ds[var].attrs
    out_xr.coords["latitude"].attrs = ds["lat"].attrs
    out_xr.coords["longitude"].attrs = ds["lon"].attrs
    out_xr.coords["elev"].attrs = ds["elev"].attrs

    # Add Spatial Reference in recognizable format
    out_xr.rio.write_crs(ds.spatial_ref, inplace=True)

    return out_xr

def apply_glt(ds_array, glt_array, fill_value=-9999, GLT_NODATA_VALUE=0):
    """
    Applies the GLT array to a numpy array of either 2 or 3 dimensions to orthorectify the data.

    Args:
        ds_array (numpy.ndarray): A numpy array of the desired variable.
        glt_array (numpy.ndarray): A GLT array constructed from EMIT GLT data.
        fill_value (int, optional): The value to fill in the output array where the GLT array has no data. Defaults to -9999.
        GLT_NODATA_VALUE (int, optional): The value in the GLT array that indicates no data. Defaults to 0.

    Returns:
        numpy.ndarray: A numpy array of orthorectified data.
    """

    # Build Output Dataset
    if ds_array.ndim == 2:
        ds_array = ds_array[:, :, np.newaxis]
    out_ds = np.full(
        (glt_array.shape[0], glt_array.shape[1], ds_array.shape[-1]),
        fill_value,
        dtype=np.float32,
    )
    valid_glt = np.all(glt_array != GLT_NODATA_VALUE, axis=-1)

    # Adjust for One based Index - make a copy to prevent decrementing multiple times inside ortho_xr when applying the glt to elev
    glt_array_copy = glt_array.copy()
    glt_array_copy[valid_glt] -= 1
    out_ds[valid_glt, :] = ds_array[
        glt_array_copy[valid_glt, 1], glt_array_copy[valid_glt, 0], :
    ]
    return out_ds

# Function to Calculate the Lat and Lon Vectors/Coordinate Grid
def coord_vects(ds):
    """
    This function calculates the Lat and Lon Coordinate Vectors using the GLT and Metadata from an EMIT dataset read into xarray.

    Parameters:
    ds: an xarray.Dataset containing the root variable and metadata of an EMIT dataset
    loc: an xarray.Dataset containing the 'location' group of an EMIT dataset

    Returns:
    lon, lat (numpy.array): longitute and latitude array grid for the dataset

    """
    # Retrieve Geotransform from Metadata
    GT = ds.geotransform
    # Create Array for Lat and Lon and fill
    dim_x = ds.glt_x.shape[1]
    dim_y = ds.glt_x.shape[0]
    lon = np.zeros(dim_x)
    lat = np.zeros(dim_y)
    # Note: no rotation for EMIT Data
    for x in np.arange(dim_x):
        x_geo = (GT[0] + 0.5 * GT[1]) + x * GT[1]  # Adjust coordinates to pixel-center
        lon[x] = x_geo
    for y in np.arange(dim_y):
        y_geo = (GT[3] + 0.5 * GT[5]) + y * GT[5]
        lat[y] = y_geo
    return lon, lat

def viz_emit(
    ds,
    wavelengths,
    cmap="viridis",
    frame_width=720,
    method="nearest",
    ortho=True,
    aspect="equal",
    tiles="ESRI",
    alpha=0.8,
    title=None,
    options={},
    **kwargs,
):
    """
    Visualizes the reflectance data from a given dataset at specific wavelengths.

    Args:
        ds (xarray.Dataset or str): The dataset containing the reflectance data or the file path to the dataset.
        wavelengths (array-like): The specific wavelengths to visualize.
        cmap (str, optional): The colormap to use. Defaults to "viridis".
        frame_width (int, optional): The width of the frame. Defaults to 720.
        method (str, optional): The method to use for data selection. Defaults to "nearest".
        ortho (bool, optional): If True, the function will return an orthorectified image. Defaults to True.
        aspect (str, optional): The aspect ratio of the plot. Defaults to "equal".
        tiles (str, optional): The tile source to use for the background map. Defaults to "ESRI".
        alpha (float, optional): The alpha value for the image. Defaults to 0.8.
        title (str, optional): The title of the plot. If None, a default title will be generated. Defaults to None.
        options (dict, optional): Additional options to be passed to `hvplot.image`. Defaults to {}.
        **kwargs: Additional keyword arguments to be passed to `hvplot.image`.

    Returns:
        hvplot.Plot: The image plot of the reflectance data at the specified wavelengths.
    """
    import hvplot.xarray

    if isinstance(ds, str):
        ds = read_emit(ds, ortho=ortho)

    if not isinstance(wavelengths, list):
        wavelengths = [wavelengths]
    example = ds.sel(wavelength=wavelengths, method=method)

    wavelengths = ", ".join([f"{w:.3f}" for w in example["wavelength"]])

    if title is None:
        title = f"Reflectance at {wavelengths} {example.wavelength.units}"

    if ortho:
        image = example.hvplot.image(
            cmap=cmap,
            geo=ortho,
            tiles=tiles,
            alpha=alpha,
            frame_width=frame_width,
            **kwargs,
        ).opts(title=title, **options)
    else:
        image = example.hvplot.image(
            cmap=cmap, aspect=aspect, alpha=alpha, frame_width=frame_width, **kwargs
        ).opts(title=title, **options)

    return image

url_rfl = "https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230402T195040_2309213_004/EMIT_L2A_RFL_001_20230402T195040_2309213_004.nc"
filepath_rfl = "EMIT_L2A_RFL_001_20230402T195040_2309213_004.nc"
hypercoast.download_file(url_rfl)

url_mask = "https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230402T195040_2309213_004/EMIT_L2A_MASK_001_20230402T195040_2309213_004.nc"
filepath_mask = "EMIT_L2A_MASK_001_20230402T195040_2309213_004.nc"
hypercoast.download_file(url_mask)

# Quality flag keys
# 0 = 'Cloud flag'
# 1 = 'Cirrus flag'
# 2 = 'Water flag'
# 3 = 'Spacecraft Flag'
# 4 = 'Dilated Cloud Flag'
# 5 = 'AOD550'
# 6 = 'H2O (g cm-2)'
# 7 = 'Aggregate Flag'

# Quality bands that I want to use
quality_flags=[0,1,3]

# Prints flags used (double check)
mask_parameters_ds = xr.open_dataset(filepath_mask, engine="h5netcdf", group="sensor_band_parameters")
flags_used = mask_parameters_ds["mask_bands"].data[quality_flags]
print(f"Flags used: {flags_used}")

# Creates quality mask based on desired quality flags
q_mask = quality_mask(filepath_mask, quality_flags)

# Creates band mask
b_mask = band_mask(filepath_mask)

# Xarray with masks but not orthorectified
masked_ds = emit_xarray(filepath_rfl, qmask = q_mask, unpacked_bmask= b_mask)

final_xr = ortho_xr(ds=masked_ds, GLT_NODATA_VALUE=0, fill_value=-9999)

xr_wavelength681 = final_xr.sel(wavelength=slice(678,685)) #678.5539
array_relectance681 = xr_wavelength681.reflectance

xr_wavelength709 = final_xr.sel(wavelength=slice(706,712)) #708.38354
array_relectance709 = xr_wavelength709.reflectance.values

xr_wavelength665 = final_xr.sel(wavelength=slice(663,668)) #663.6411
array_relectance665 = xr_wavelength665.reflectance.values

# Wavelengths closests to target wavelength
wvl_681 = array_relectance681['wavelength'].values[0]
wvl_709 = xr_wavelength709['wavelength'].values[0]
wvl_665 = xr_wavelength665['wavelength'].values[0]

CI = - ((array_relectance681 - array_relectance665 - (array_relectance709 - array_relectance665)) * ((wvl_681 - wvl_665 / wvl_709 - wvl_665)))

xr_CI = xr.DataArray(CI)

CI_map = viz_emit(ds = xr_CI, wavelengths = 681, cmap = 'gnuplot2', title = 'CI for 04/02/2023')
CI_map

xr_wavelength714 = final_xr.sel(wavelength=slice(712,716)) #715.84094
array_relectance714 = xr_wavelength714.reflectance

xr_wavelength754 = final_xr.sel(wavelength=slice(752,756)) #753.1359
array_relectance754 = xr_wavelength754.reflectance.values

xr_wavelength654 = final_xr.sel(wavelength=slice(651,657)) #656.1857
array_relectance654 = xr_wavelength654.reflectance.values

# Wavelengths closests to target wavelength
wvl_714 = array_relectance714['wavelength'].values[0]
wvl_754 = xr_wavelength754['wavelength'].values[0]
wvl_654 = xr_wavelength654['wavelength'].values[0]

SLH = array_relectance714 - (array_relectance654 + (((array_relectance754 - array_relectance654) / (wvl_754 - wvl_654)) * (wvl_714 - wvl_654)))

xr_SLH = xr.DataArray(SLH)

SLH_map = viz_emit(ds = xr_SLH, wavelengths = 714, title = 'SLH for 04/02/2023')
SLH_map
